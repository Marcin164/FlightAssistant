# Dokumentacja Wektoryzatora Dokument贸w

##  Opis

Skrypt `vektorizer.py` zawiera klas `DocumentVectorizer`, kt贸ra umo偶liwia:
- **Wczytywanie** dokument贸w txt z folderu
- **Wektoryzacj** dokument贸w za pomoc TF-IDF
- **Zapisywanie** wektor贸w w formie, kt贸r mo偶na ponownie u偶y
- **Wyszukiwanie** podobnych dokument贸w za pomoc cosine similarity

##  Szybki Start

### 1. Wygenerowanie i zapisanie wektor贸w

```bash
python vektorizer.py
```

To:
- Wczyta wszystkie pliki `.txt` z `C:\Users\Albert\Desktop\STUDIA\Sem2\Zastosowanie AI\Regulaminy\txts`
- Wektoryzuje je za pomoc TF-IDF
- Zapisze wektory w folderze `./vectors_db`

### 2. U偶ycie zapisanych wektor贸w w innym projekcie

```python
from vektorizer import DocumentVectorizer

# Wczytaj wektory
vectorizer = DocumentVectorizer()
vectorizer.load('./vectors_db')

# Szukaj podobnych dokument贸w
results = vectorizer.search(query="passenger baggage policy", top_k=3)
print(results)
```

##  Struktura Zapisanych Danych

Po uruchomieniu skryptu w folderze `./vectors_db` pojawi si:

```
vectors_db/
 vectors.pkl          # Wektory TF-IDF (format pickle)
 vectorizer.pkl       # Wektoryzator TF-IDF (do transformacji nowych zapyta)
 metadata.csv         # Metadane dokument贸w (nazwa, cie偶ka, rozmiar)
 stats.txt           # Statystyka (liczba dokument贸w, wymiary wektor贸w)
```

##  Klasa DocumentVectorizer

### Inicjalizacja

```python
vectorizer = DocumentVectorizer(max_features=5000, ngram_range=(1, 2))
```

**Parametry:**
- `max_features` (int): Maksymalna liczba cech do wyodrbnienia (domylnie 5000)
- `ngram_range` (tuple): Zakres n-gram贸w (domylnie (1, 2) = unigramy i bigramy)

### Metody

#### `load_documents(folder_path)`
Wczytuje wszystkie pliki `.txt` z podanego folderu.

```python
vectorizer.load_documents(r"C:\path\to\documents")
```

#### `vectorize()`
Wektoryzuje zaadowane dokumenty za pomoc TF-IDF.

```python
vectors = vectorizer.vectorize()
```

#### `save(output_dir='./vectors_db')`
Zapisuje wektory i metadane do pliku.

```python
vectorizer.save('./my_vectors')
```

#### `load(vectors_dir='./vectors_db')`
Wczytuje wektory z pliku (do u偶ycia w innym projekcie).

```python
vectorizer.load('./vectors_db')
```

#### `search(query, top_k=5)`
Szukaj podobnych dokument贸w za pomoc cosine similarity.

```python
# Szukaj na podstawie tekstu
results = vectorizer.search("passenger baggage policy", top_k=3)

# Szukaj na podstawie indeksu dokumentu
results = vectorizer.search(query=0, top_k=3)
```

**Zwraca:** DataFrame z wynikami zawierajcy:
- `index`: Indeks dokumentu
- `filename`: Nazwa pliku
- `similarity_score`: Wynik cosine similarity (0-1)
- `size`: Rozmiar pliku

#### `get_feature_names()`
Zwraca nazwy wszystkich cech (s贸w) w sowniku.

```python
words = vectorizer.get_feature_names()
print(f"Liczba s贸w: {len(words)}")
```

##  Przykady U偶ycia

### Przykad 1: Podstawowe u偶ycie

```python
from vektorizer import DocumentVectorizer

vectorizer = DocumentVectorizer()
vectorizer.load_documents(r"C:\path\to\documents")
vectorizer.vectorize()
vectorizer.save('./my_vectors')
```

### Przykad 2: Szukanie w zapisanej bazie

```python
from vektorizer import DocumentVectorizer

vectorizer = DocumentVectorizer()
vectorizer.load('./my_vectors')

# Szukaj na podstawie zapytania tekstowego
results = vectorizer.search("baggage allowance weight", top_k=5)
print(results)
```

### Przykad 3: Szukanie na podstawie istniejcego dokumentu

```python
# Szukaj dokument贸w podobnych do pierwszego dokumentu
results = vectorizer.search(query=0, top_k=3)
print(results)

# Znajd藕 dokumenty podobne do drugiego
results = vectorizer.search(query=1, top_k=3)
```

### Przykad 4: Dostp do metadanych

```python
# Wywietl informacje o wszystkich dokumentach
for i, meta in enumerate(vectorizer.metadata):
    print(f"{i}: {meta['filename']} ({meta['size']} bytes)")
```

##  Zalety TF-IDF + Pickle

| Aspekt | Opis |
|--------|------|
| **Kompaktowo** | Wektory sparse (rzadkie) zajmuj mao miejsca |
| **Wydajno** | Szybkie wczytanie i wyszukiwanie |
| **Przenono** | atwo przenie midzy projektami |
| **Bezpieczestwo** | Pickle przechowuje stan wektoryzatora |
| **Skalowo** | Mo偶e obsugiwa tysice dokument贸w |

##  Cosine Similarity

Cosine similarity mierzy podobiestwo midzy wektorami tekstu:
- **1.0** = Identyczne dokumenty
- **0.5** = Umiarkowanie podobne
- **0.0** = Cakowicie r贸偶ne

##  Pliki Projektowe

- `vektorizer.py` - G贸wny skrypt z klas DocumentVectorizer
- `use_vectors.py` - Przykad u偶ycia wektor贸w w nowym projekcie
- `vectors_db/` - Folder z zapisanymi wektorami i metadanymi

## 锔 Wymagania

```
scikit-learn>=1.0.0
pandas>=1.3.0
numpy>=1.20.0
```

Zainstaluj za pomoc:
```bash
pip install scikit-learn pandas numpy
```

##  Dostosowanie

### Zmiana liczby cech:
```python
vectorizer = DocumentVectorizer(max_features=10000)
```

### Zmiana n-gram贸w:
```python
# Tylko unigramy
vectorizer = DocumentVectorizer(ngram_range=(1, 1))

# Unigramy, bigramy i trigramy
vectorizer = DocumentVectorizer(ngram_range=(1, 3))
```

### Zmiana folderu wyjciowego:
```python
vectorizer.save(r"C:\my\custom\path")
vectorizer.load(r"C:\my\custom\path")
```

##  Rozwizywanie Problem贸w

**Problem:** "Brak zaadowanych dokument贸w"
- Rozwizanie: Upewnij si 偶e uruchomie `load_documents()` przed `vectorize()`

**Problem:** "FileNotFoundError w load()"
- Rozwizanie: Sprawd藕 cie偶k do `vectors_db` i upewnij si 偶e istniej pliki `.pkl`

**Problem:** Niska dokadno wyszukiwania
- Rozwizanie: Zwiksz `max_features` lub dostosuj `ngram_range`

##  Kontakt

W razie pyta, sprawd藕 kod w pliku `vektorizer.py` - zawiera szczeg贸owe komentarze.
