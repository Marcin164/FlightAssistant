"""
Zaawansowana konfiguracja i przyk≈Çady u≈ºycia DocumentVectorizer
"""

from vektorizer import DocumentVectorizer
import os


def example_advanced_vectorization():
    """Przyk≈Çad zaawansowanej wektoryzacji z r√≥≈ºnymi parametrami."""

    print("=" * 70)
    print("ZAAWANSOWANA WEKTORYZACJA Z R√ì≈ªNYMI PARAMETRAMI")
    print("=" * 70)

    documents_folder = r"C:\Users\Albert\Desktop\STUDIA\Sem2\Zastosowanie AI\Regulaminy\txts"

    # Konfiguracja 1: Ma≈Ço cech (szybkie, ale mniej dok≈Çadne)
    print("\nüìå Konfiguracja 1: Ma≈Ço cech (max_features=1000)")
    print("-" * 70)
    v1 = DocumentVectorizer(max_features=1000, ngram_range=(1, 2))
    v1.load_documents(documents_folder)
    v1.vectorize()
    print(f"Wymiary wektor√≥w: {v1.vectors.shape}")
    v1.save("./vectors_db_small")

    # Konfiguracja 2: Du≈ºo cech (dok≈Çadniejsze, ale wolniejsze)
    print("\nüìå Konfiguracja 2: Du≈ºo cech (max_features=10000)")
    print("-" * 70)
    v2 = DocumentVectorizer(max_features=10000, ngram_range=(1, 2))
    v2.load_documents(documents_folder)
    v2.vectorize()
    print(f"Wymiary wektor√≥w: {v2.vectors.shape}")
    # v2.save("./vectors_db_large")  # Skomentowane, aby nie zajmowaƒá miejsca

    # Konfiguracja 3: Tylko unigramy
    print("\nüìå Konfiguracja 3: Tylko unigramy (ngram_range=(1, 1))")
    print("-" * 70)
    v3 = DocumentVectorizer(max_features=5000, ngram_range=(1, 1))
    v3.load_documents(documents_folder)
    v3.vectorize()
    print(f"Wymiary wektor√≥w: {v3.vectors.shape}")
    # v3.save("./vectors_db_unigrams")

    # Konfiguracja 4: Unigramy i bigramy i trigramy
    print("\nüìå Konfiguracja 4: Unigramy, bigramy i trigramy (ngram_range=(1, 3))")
    print("-" * 70)
    v4 = DocumentVectorizer(max_features=5000, ngram_range=(1, 3))
    v4.load_documents(documents_folder)
    v4.vectorize()
    print(f"Wymiary wektor√≥w: {v4.vectors.shape}")
    # v4.save("./vectors_db_trigrams")

    print("\n‚ú® Gotowe! R√≥≈ºne konfiguracje zosta≈Çy wygenerowane.")


def example_batch_search():
    """Przyk≈Çad wyszukiwania batch - wiele zapyta≈Ñ naraz."""

    print("\n" + "=" * 70)
    print("WYSZUKIWANIE BATCH - WIELE ZAPYTA≈É NARAZ")
    print("=" * 70)

    vectors_dir = "./vectors_db"
    if not os.path.exists(vectors_dir):
        print(f"‚ùå Katalog {vectors_dir} nie istnieje!")
        return

    vectorizer = DocumentVectorizer()
    vectorizer.load(vectors_dir)

    # Lista zapyta≈Ñ
    queries = [
        "baggage allowance weight limit",
        "flight cancellation refund policy",
        "passenger rights compensation",
        "insurance coverage claim",
        "special services charges fees"
    ]

    print(f"\nüîç Wyszukiwanie {len(queries)} zapyta≈Ñ...\n")

    for i, query in enumerate(queries, 1):
        print(f"{i}. Zapytanie: '{query}'")
        results = vectorizer.search(query, top_k=2)
        for _, row in results.iterrows():
            score = row['similarity_score']
            print(f"   ‚Üí {row['filename']:20} (wynik: {score:.4f})")
        print()


def example_similarity_matrix():
    """Przyk≈Çad: Wygeneruj macierz podobie≈Ñstwa miƒôdzy wszystkimi dokumentami."""

    print("\n" + "=" * 70)
    print("MACIERZ PODOBIE≈ÉSTWA MIƒòDZY DOKUMENTAMI")
    print("=" * 70)

    vectors_dir = "./vectors_db"
    if not os.path.exists(vectors_dir):
        print(f"‚ùå Katalog {vectors_dir} nie istnieje!")
        return

    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np

    vectorizer = DocumentVectorizer()
    vectorizer.load(vectors_dir)

    # Oblicz macierz podobie≈Ñstwa
    similarity_matrix = cosine_similarity(vectorizer.vectors)

    print("\nüìä Macierz cosine similarity miƒôdzy dokumentami:\n")

    # Wy≈õwietl nag≈Ç√≥wki
    filenames = [meta['filename'] for meta in vectorizer.metadata]
    max_len = max(len(f) for f in filenames)

    # Nag≈Ç√≥wek kolumn
    header = " " * (max_len + 2)
    for fname in filenames:
        header += f"{fname[:8]:>10}"
    print(header)

    # Dane
    for i, fname in enumerate(filenames):
        row = f"{fname:<{max_len}}"
        for j in range(len(filenames)):
            score = similarity_matrix[i][j]
            row += f"{score:>10.3f}"
        print(row)


def example_feature_analysis():
    """Przyk≈Çad: Analiza najwa≈ºniejszych cech (s≈Ç√≥w) dla ka≈ºdego dokumentu."""

    print("\n" + "=" * 70)
    print("ANALIZA NAJWA≈ªNIEJSZYCH CECH (S≈Å√ìW) DLA KA≈ªDEGO DOKUMENTU")
    print("=" * 70)

    vectors_dir = "./vectors_db"
    if not os.path.exists(vectors_dir):
        print(f"‚ùå Katalog {vectors_dir} nie istnieje!")
        return

    import numpy as np

    vectorizer = DocumentVectorizer()
    vectorizer.load(vectors_dir)

    feature_names = vectorizer.get_feature_names()

    # Dla ka≈ºdego dokumentu znale≈∫ top 10 s≈Ç√≥w
    for i, meta in enumerate(vectorizer.metadata):
        print(f"\nüìÑ Dokument {i+1}: {meta['filename']}")
        print("-" * 70)

        # Pobierz wektor dla dokumentu i
        vector = vectorizer.vectors[i].toarray()[0]

        # Znajd≈∫ top 10 indeks√≥w
        top_indices = np.argsort(vector)[-10:][::-1]

        print("Top 10 najwa≈ºniejszych s≈Ç√≥w:")
        for rank, idx in enumerate(top_indices, 1):
            word = feature_names[idx]
            score = vector[idx]
            if score > 0:  # Wy≈õwietl tylko je≈õli wynik > 0
                print(f"  {rank:2d}. {word:30} (waga: {score:.4f})")


def main():
    """Uruchom wszystkie przyk≈Çady."""

    try:
        # Przyk≈Çad 1: Zaawansowana wektoryzacja
        example_advanced_vectorization()

        # Przyk≈Çad 2: Wyszukiwanie batch
        example_batch_search()

        # Przyk≈Çad 3: Macierz podobie≈Ñstwa
        example_similarity_matrix()

        # Przyk≈Çad 4: Analiza cech
        example_feature_analysis()

    except Exception as e:
        print(f"\n‚ùå B≈ÇƒÖd: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
